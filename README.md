ğŸ§  NumPy for Deep Learning

Mastering the mathematical engine behind modern AI

This repository is a comprehensive guide to using NumPy specifically for Deep Learning applications â€” from tensor manipulation to implementing core functions like Softmax, ReLU, and Gumbel-Max.

ğŸš€ Overview

Deep Learning is essentially:

Linear Algebra + Calculus + Code

While high-level frameworks like PyTorch and TensorFlow are industry standards, understanding the underlying NumPy implementations is crucial for:

Debugging neural networks

Building custom layers

Research experimentation

Strengthening mathematical intuition

ğŸ“Œ Key Concepts Covered
ğŸ”¹ Tensor Surgery

Advanced slicing

np.stack vs np.concatenate

Axis manipulation

ğŸ”¹ Activation Functions

Vectorized implementation of:

ReLU

Leaky ReLU

Softmax

ğŸ”¹ Data Augmentation

np.flip

np.roll

np.pad

ğŸ”¹ Stochastic Tricks

Implementing the Gumbel-Max Trick for differentiable sampling

ğŸ”¹ Normalization

Calculating mean and variance across specific axes using keepdims=True

ğŸ› ï¸ Installation & Setup

To run the notebooks locally:

git clone https://github.com/SYEDFAIZAN1987/NumpyForDeepLearning.git
cd NumpyForDeepLearning
pip install numpy jupyterlab
ğŸ“– Deep Dive: Core Implementations
1ï¸âƒ£ The Softmax Function

Essential for multi-class classification, implemented using the axis=-1 and keepdims=True pattern to support batch processing.

ğœ
(
ğ‘§
)
ğ‘–
=
ğ‘’
ğ‘§
ğ‘–
âˆ‘
ğ‘—
=
1
ğ¾
ğ‘’
ğ‘§
ğ‘—
Ïƒ(z)
i
	â€‹

=
âˆ‘
j=1
K
	â€‹

e
z
j
	â€‹

e
z
i
	â€‹

	â€‹

2ï¸âƒ£ ReLU Activation (Non-Linearity)

Implemented via:

np.maximum(0, x)

This effectively â€œdeactivatesâ€ neurons receiving negative signals.

3ï¸âƒ£ Gumbel-Max Sampling

A technique used in LLMs and Reinforcement Learning to sample from categorical distributions.

# Adding Gumbel noise to logits
noise = np.random.gumbel(0, 1, logits.shape)
sample = np.argmax(logits + noise)
ğŸ“‚ Repository Structure
â”œâ”€â”€ NumpyNotes.ipynb      # Main workbook with code & explanations
â”œâ”€â”€ README.md             # Documentation
â””â”€â”€ .gitignore            # Prevents unnecessary files (e.g., .ipynb_checkpoints)
ğŸ¤ Contributing

Found a more efficient way to implement a layer? Open a PR!

Steps:

Fork the project

Create your feature branch

git checkout -b feature/AmazingFeature

Commit your changes

git commit -m "Add some AmazingFeature"

Push to the branch

git push origin feature/AmazingFeature

Open a Pull Request

ğŸ‘¤ Author

Syed Faizan
GitHub: @SYEDFAIZAN1987
